diff --git a/kernel/vpsadminos.c b/kernel/vpsadminos.c
index 895221b90512..852d179463b7 100644
--- a/kernel/vpsadminos.c
+++ b/kernel/vpsadminos.c
@@ -9,6 +9,25 @@
 #include <linux/xarray.h>
 #include <asm/page.h>
 #include "sched/sched.h"
+#include <linux/vpsadminos-livepatch.h>
+#include "kpatch-macros.h"
+char old_uname[65];
+char new_uname[65];
+
+static int patch(patch_object *obj)
+{
+	scnprintf(new_uname, 64, "%s.%s", LIVEPATCH_ORIG_KERNEL_VERSION,
+	    LIVEPATCH_NAME);
+	scnprintf(old_uname, 64, "%s", init_uts_ns.name.release);
+	scnprintf(init_uts_ns.name.release, 64, "%s", new_uname);
+	return 0;
+}
+KPATCH_PRE_PATCH_CALLBACK(patch);
+static void unpatch(patch_object *obj)
+{
+	scnprintf(init_uts_ns.name.release, 64, "%s", old_uname);
+}
+KPATCH_POST_UNPATCH_CALLBACK(unpatch);
 
 int online_cpus_in_cpu_cgroup(struct task_struct *p)
 {
diff --git a/net/core/rtnetlink.c b/net/core/rtnetlink.c
index 3c9c2d6e3b92..8ad5643c5ab3 100644
--- a/net/core/rtnetlink.c
+++ b/net/core/rtnetlink.c
@@ -2147,7 +2147,7 @@ static int rtnl_dump_ifinfo(struct sk_buff *skb, struct netlink_callback *cb)
 out_err:
 	cb->args[1] = idx;
 	cb->args[0] = h;
-	cb->seq = net->dev_base_seq;
+	cb->seq = tgt_net->dev_base_seq;
 	nl_dump_check_consistent(cb, nlmsg_hdr(skb));
 	if (netnsid >= 0)
 		put_net(tgt_net);
diff --git a/net/netfilter/nf_conntrack_core.c b/net/netfilter/nf_conntrack_core.c
index 8369af0c50ea..18f186fb3239 100644
--- a/net/netfilter/nf_conntrack_core.c
+++ b/net/netfilter/nf_conntrack_core.c
@@ -75,9 +75,6 @@ static __read_mostly struct kmem_cache *nf_conntrack_cachep;
 static DEFINE_SPINLOCK(nf_conntrack_locks_all_lock);
 static __read_mostly bool nf_conntrack_locks_all;
 
-/* serialize hash resizes and nf_ct_iterate_cleanup */
-static DEFINE_MUTEX(nf_conntrack_mutex);
-
 #define GC_SCAN_INTERVAL	(120u * HZ)
 #define GC_SCAN_MAX_DURATION	msecs_to_jiffies(10)
 
@@ -2178,31 +2175,28 @@ get_next_corpse(int (*iter)(struct nf_conn *i, void *data),
 	spinlock_t *lockp;
 
 	for (; *bucket < nf_conntrack_htable_size; (*bucket)++) {
-		struct hlist_nulls_head *hslot = &nf_conntrack_hash[*bucket];
-
-		if (hlist_nulls_empty(hslot))
-			continue;
-
 		lockp = &nf_conntrack_locks[*bucket % CONNTRACK_LOCKS];
 		local_bh_disable();
 		nf_conntrack_lock(lockp);
-		hlist_nulls_for_each_entry(h, n, hslot, hnnode) {
-			if (NF_CT_DIRECTION(h) != IP_CT_DIR_REPLY)
-				continue;
-			/* All nf_conn objects are added to hash table twice, one
-			 * for original direction tuple, once for the reply tuple.
-			 *
-			 * Exception: In the IPS_NAT_CLASH case, only the reply
-			 * tuple is added (the original tuple already existed for
-			 * a different object).
-			 *
-			 * We only need to call the iterator once for each
-			 * conntrack, so we just use the 'reply' direction
-			 * tuple while iterating.
-			 */
-			ct = nf_ct_tuplehash_to_ctrack(h);
-			if (iter(ct, data))
-				goto found;
+		if (*bucket < nf_conntrack_htable_size) {
+			hlist_nulls_for_each_entry(h, n, &nf_conntrack_hash[*bucket], hnnode) {
+				if (NF_CT_DIRECTION(h) != IP_CT_DIR_REPLY)
+					continue;
+				/* All nf_conn objects are added to hash table twice, one
+				 * for original direction tuple, once for the reply tuple.
+				 *
+				 * Exception: In the IPS_NAT_CLASH case, only the reply
+				 * tuple is added (the original tuple already existed for
+				 * a different object).
+				 *
+				 * We only need to call the iterator once for each
+				 * conntrack, so we just use the 'reply' direction
+				 * tuple while iterating.
+				 */
+				ct = nf_ct_tuplehash_to_ctrack(h);
+				if (iter(ct, data))
+					goto found;
+			}
 		}
 		spin_unlock(lockp);
 		local_bh_enable();
@@ -2220,20 +2214,26 @@ get_next_corpse(int (*iter)(struct nf_conn *i, void *data),
 static void nf_ct_iterate_cleanup(int (*iter)(struct nf_conn *i, void *data),
 				  void *data, u32 portid, int report)
 {
-	unsigned int bucket = 0;
+	unsigned int bucket = 0, sequence;
 	struct nf_conn *ct;
 
 	might_sleep();
 
-	mutex_lock(&nf_conntrack_mutex);
-	while ((ct = get_next_corpse(iter, data, &bucket)) != NULL) {
-		/* Time to push up daises... */
+	for (;;) {
+		sequence = read_seqcount_begin(&nf_conntrack_generation);
 
-		nf_ct_delete(ct, portid, report);
-		nf_ct_put(ct);
-		cond_resched();
+		while ((ct = get_next_corpse(iter, data, &bucket)) != NULL) {
+			/* Time to push up daises... */
+
+			nf_ct_delete(ct, portid, report);
+			nf_ct_put(ct);
+			cond_resched();
+		}
+
+		if (!read_seqcount_retry(&nf_conntrack_generation, sequence))
+			break;
+		bucket = 0;
 	}
-	mutex_unlock(&nf_conntrack_mutex);
 }
 
 struct iter_data {
@@ -2463,10 +2463,8 @@ int nf_conntrack_hash_resize(unsigned int hashsize)
 	if (!hash)
 		return -ENOMEM;
 
-	mutex_lock(&nf_conntrack_mutex);
 	old_size = nf_conntrack_htable_size;
 	if (old_size == hashsize) {
-		mutex_unlock(&nf_conntrack_mutex);
 		kvfree(hash);
 		return 0;
 	}
@@ -2502,8 +2500,6 @@ int nf_conntrack_hash_resize(unsigned int hashsize)
 	nf_conntrack_all_unlock();
 	local_bh_enable();
 
-	mutex_unlock(&nf_conntrack_mutex);
-
 	synchronize_net();
 	kvfree(old_hash);
 	return 0;
diff --git a/net/netfilter/nft_payload.c b/net/netfilter/nft_payload.c
index 551e0d6cf63d..74c220eeec1a 100644
--- a/net/netfilter/nft_payload.c
+++ b/net/netfilter/nft_payload.c
@@ -62,7 +62,7 @@ nft_payload_copy_vlan(u32 *d, const struct sk_buff *skb, u8 offset, u8 len)
 			return false;
 
 		if (offset + len > VLAN_ETH_HLEN + vlan_hlen)
-			ethlen -= offset + len - VLAN_ETH_HLEN + vlan_hlen;
+			ethlen -= offset + len - VLAN_ETH_HLEN - vlan_hlen;
 
 		memcpy(dst_u8, vlanh + offset - vlan_hlen, ethlen);
 
